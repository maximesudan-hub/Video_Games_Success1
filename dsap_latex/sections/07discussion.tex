\section{Discussion}

The results highlight clear differences in predictive performance across modeling approaches. Linear baselines (OLS/Ridge) provide interpretable benchmarks but underperform tree-based models in predictive accuracy. HistGradientBoosting delivers the best regression performance, while Random Forest provides a strong balance between accuracy and interpretability through feature importance.

Across models, engagement and visibility variables (Critic/User counts) consistently emerge as top predictors, suggesting that attention and reach matter as much as average review quality. Platform and publisher effects also contribute substantially, indicating that distribution channels and marketing capabilities shape commercial outcomes.

Clustering based on numeric signals yields three exploratory groups with partial separation, consistent with the moderate silhouette score, and provides descriptive context rather than causal or predictive claims.

Overall, the findings support the central research question: success is not driven by a single factor but by a combination of reception, exposure, and market context. The choice of model depends on the objective: HistGradientBoosting for best prediction, Random Forest for explanatory insights. Feature importance reflects predictive relevance and should not be interpreted as causal effects.
Given the observational nature of the dataset, all reported relationships should be interpreted as descriptive associations rather than causal mechanisms.

\paragraph{Limitations}
The analysis relies on post-release signals (critic and user feedback), which can be influenced by popularity and marketing. This introduces endogeneity and limits causal interpretation. In addition, the dataset does not include direct measures of marketing spend, franchise strength, or advertising reach, which are likely important determinants of sales.

\paragraph{Practical implications}
For decision-making, engagement signals (counts) provide early indicators of market traction. However, they should be complemented with pre-release indicators in future work to improve causal interpretability.
\paragraph{Endogeneity and interpretation}
Variables such as Critic\_Count and User\_Count reflect attention and may increase \emph{because} a game is already successful. As a result, these features can inflate predictive performance without proving causality. The report therefore treats feature importance as an explanatory signal rather than a causal mechanism.

\paragraph{Predictive vs. explanatory goals}
The project is explicitly predictive: the goal is to estimate sales and identify strong correlates. This is different from estimating causal effects. A high-performing model can still rely on variables that are not actionable at release time. This distinction is emphasized to avoid over-interpretation of coefficients or importances.

\paragraph{Actionability and temporal shifts}
Some predictors are actionable (platform selection, release timing), while others are not (post-release review counts). The dataset ends in 2016, which limits generalization to current markets.

% Robustness and generalizability discussed briefly in Conclusion/Future Directions.
